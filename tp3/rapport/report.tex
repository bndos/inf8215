% Created 2022-04-15 Fri 00:13
% Intended LaTeX compiler: pdflatex
\documentclass[12pt]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[french]{babel}
\input{packages}
\input{config}
\onehalfspacing
\addbibresource{template.bib}
\let\cite\parencite
\date{}
\title{Template}
\begin{document}

\begin{ctitlepage}

\cours{INF8215}

\groupe{Groupe 01}

\titre{\textbf{TP3} \\
Classifications multiclasses:\\
légumes secs}

\vspace{.1in}

\textbf{Par} \\
Brando, Tovar \textbf{1932052} \\
Vega, Estefan \textbf{1934346} \\
Équipe: \textbf{BrandiniStifini} \\

\vspace{.5in}

Le \today

\end{ctitlepage}

\newpage
\tableofcontents
\newpage


\section{Contexte}
\label{sec:orgd6071ac}
Dans ce travail pratique, il nous était demander de classifier des légumes secs dans leur catégorie respectives. Il y en avait 7 en tout; Sira, Horoz, Dermason, Barbunya, Cali, Bombay, Seker et nous devions déterminer la catégorie à l'aide de 16 \emph{features}. Nous avions donc à résoudre un problème de classification multiclasses. Nous avons décider d'utiliser la librairie \emph{scikit-learn} et le modèle que nous avons utilisé se base sur les machines à vecteurs de support (\emph{SVC OneVsOneClassifier}). Nous avons aussi exploré d'autres modèle telles que celui basée sur la descente de gradient stochastique (\emph{SGDClassifier}) et celle basée sur les forêts aléatoires (\emph{RandomForestClassifier})

\section{Prétraitement}
\label{sec:orgec3463b}
Avant de commencé à résoudre le problème, il est utile de se familiariser avec les données. Nos données étaient constitué de 16 \emph{features}. Il y avait 6000 données de test. Nous avons commencé par voir s'il manquait des valeurs dans certaines de no données test ce qui n'était pas le cas. Nous avons ensuite regardé si nos donées étaient balancées.
\vspace{5mm}

\begin{minipage}{.45\textwidth}
\captionof{figure}{Diagramme à bandes des catégories}
\vspace*{-5mm}
\begin{center}
\includegraphics[width=\linewidth]{./.ob-jupyter/0e36c24725fa023c6e39f07bc9df640645c86811.png}
\end{center}
\label{fig:barchart}
\end{minipage}
\begin{minipage}{.55\textwidth}
\captionof{figure}{Matrice de corrélation}
\vspace*{-5mm}
\begin{center}
\includegraphics[width=\linewidth]{./.ob-jupyter/da88383af5d1618a3cb0bf8008eb6ce0c4c86bce.png}
\end{center}
\label{fig:heatmap}
\end{minipage}

\vspace{5mm}

Il a été intéressant de voir qu'il y a présence de débalancement (\hyperref[fig:barchart]{figure 1}) et que certains attributs étaient très corrélés entre eux soit > 0.9 ou < -0.9 (\hyperref[fig:heatmap]{figure 2}). Nous avons essayer de retirer les attributs corrélées, mais il n'y a pas vraiment eu de gain et nous avons donc décider de garder tous les attributs.

Une fois les analyse de données terminées, nous avons dû faire quelques changement dans les données afin de pouvoir utiliser notre modèle. Nous avons en premier lieu, dû transformer les valeurs de X\_train (attributs) en float. Nous avons ensuite retirer les valeurs de \emph{ID} dans X\_train et y\_train. Nous pouvions ainsi entrainer notre modèle. Étant données les mauvais résultats initiaux, nous avons dû faire appel à la normalisation. Nous sommes donc passées d'une précision de 0.268 à une de 0.933 sur le classificateur SVM.

\section{Méthodologie}
\label{sec:org035eddf}
Le classificateur que nous avons choisis (\emph{SVC}) est un classificateur binaire. Il était donc nécessaire de combiner ce classificateur avec une autre méthode. Nous avons donc choisi la méthode OneVsOne (/OneVsOneClassifier). En combinant ces deux algorithmes, nous obtenons un classificateur multiclasses qui est en fait composées de plusieurs classificateurs binaire. Dans notre cas nous avons 7 * 6 / 2 = 21 classificateurs binaires aux total.

En ce qui concerne la répartition des données, nous avons utilisé l'intégralité des données pour tester notre modèle. Nous avons pris cette décision, car nous avons utilisé en parallèle la méthode de vérification \emph{k-fold cross-validation} avec k = 10. Ainsi, les données sont diviser en 10 parties dont 9 sont utilisées pour l'entraînement et la dernière comme partie de validation.

Comme nous pouvons le voir à la figure \hyperref[fig:barchart]{figure 1}, nos données étaient assez débalancées. Nous avons fait des recherches à ce sujet et il y avait plusieurs solutions possibles. Il y avait la possibilité de faire du \emph{oversampling} et du \emph{undersampling}. Nous n'avons malheureusement pas eu de succès avec ces deux méthodes. Étant donnée que nous avons utilisés le modèle \emph{SVC} de scikit-learn, nous avions accès a l'hyperparamètre \emph{class\textsubscript{weight}} avec comme valeur \emph{balanced} qui associe un poids à chaque classe selon sa fréquence dans les données pour gérer les débalancements. Malheureusement cet hyperparamètre n'a pas impacté positivement nos résultats.

Le modèle que nous avons utilisé est basé sur les machines à vecteurs de support et il y a deux paramètres principaux à tenir en compte, \emph{C} et \emph{gamma}. D'abord il est utile de comprendre que ce modèle classifie les données de façon linéaire et que pour classifier des données de non linéaires, la méthode utilise une fonction applé noyau (\emph{kernel}). La valeur du gamma détermine à quel point les points proche et loin de la délimitation ont de l'importance. En d'autre mots, des valeurs élevé de gamma auront une meilleur délimitation, avec plus de curvatures, entre les données et donc le modèle aura plus tendance à souffrir de sur-apprentissage. À l'inverse, des
\begin{minipage}{.45\textwidth}
\vspace*{2.5mm}
valeurs faibles de gamma nous mèneront plus vers un problème de sous-apprentissage. La valeur de C nous indique plutôt notre niveau de tolérance aux erreurs et sa valeur impactera sur la généralisation de notre modèle. Une grande valeur de C augmente la precision et reduit les erreurs. Il fallait donc trouver un équilibre entre la précision de notre de modèle sur le données d'entrainement et sa capacité a généraliser. Nous avons trouver un équilibre optimale avec le valeur \emph{gamma} = 0.19 et \emph{C} = 2.8. Les impacts de ses paramètres peuvent être observés sur la \hyperref[fig:svm_c_gamma]{figure 3}.
\end{minipage}
\begin{minipage}{.55\textwidth}
\vspace*{1mm}
\captionof{figure}{SVM paramètres C et gamma}
\vspace*{-5mm}
\begin{center}
\includegraphics[width=\linewidth]{./img/svm_c_gamma.png}
\end{center}
\label{fig:svm_c_gamma}
\end{minipage}


\section{Résultats}
\label{sec:org6cd0a6f}
\section{Discussion}
\label{sec:orgd43aab5}

\section{stuff}
\label{sec:org47b493e}
\begin{minipage}{.5\textwidth}
\begin{center}
\begin{tabular}{|r|rrr|rr|}
\hline
N & N\textsuperscript{2} & N\textsuperscript{3} & N\textsuperscript{4} & sqrt(n) & sqrt[4](N)\\
\hline
1 & 1 & 1 & 1 & 1 & 1\\
2 & 4 & 8 & 16 & 1.4142 & 1.1892\\
3 & 9 & 27 & 81 & 1.7321 & 1.3161\\
\hline
\end{tabular}
\end{center}
\vspace*{-5mm}
\captionof{table}{A table}
\label{tbl:table1}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{center}
\begin{tabular}{|r|rrr|rr|}
\hline
N & N\textsuperscript{2} & N\textsuperscript{3} & N\textsuperscript{4} & sqrt(n) & sqrt[4](N)\\
\hline
1 & 1 & 1 & 1 & 1 & 1\\
2 & 4 & 8 & 16 & 1.4142 & 1.1892\\
3 & 9 & 27 & 81 & 1.7321 & 1.3161\\
\hline
\end{tabular}
\end{center}
\vspace*{-5mm}
\captionof{table}{Another table}
\label{tbl:table2}
\end{minipage}

\begin{table}[htbp]
\caption{\label{tbl:table3}Regular table}
\centering
\begin{tabular}{|r|rrr|rr|}
\hline
N & N\textsuperscript{2} & N\textsuperscript{3} & N\textsuperscript{4} & sqrt(n) & sqrt[4](N)\\
\hline
1 & 1 & 1 & 1 & 1 & 1\\
2 & 4 & 8 & 16 & 1.4142 & 1.1892\\
3 & 9 & 27 & 81 & 1.7321 & 1.3161\\
\hline
\end{tabular}
\end{table}

\begin{listing}[htbp]
\begin{minted}[breaklines=true,breakanywhere=true,linenos=true,gobble=-8,xleftmargin=20pt,bgcolor=borlandbg]{shell}
ls -l
\end{minted}
\caption{Source code}
\end{listing}

\begin{center}
\begin{tabular}{lrllrlrrl}
total & 740 &  &  &  &  &  &  & \\
-rw-rw-r-- & 1 & bndo & bndo & 1406 & Apr & 13 & 21:12 & config.tex\\
drwxrwxr-x & 2 & bndo & bndo & 4096 & Apr & 14 & 23:52 & img\\
drwxrwxr-x & 2 & bndo & bndo & 4096 & Apr & 13 & 23:34 & \_minted-report\\
-rw-rw-r-- & 1 & bndo & bndo & 459 & Apr & 13 & 21:12 & packages.tex\\
-rw-rw-r-- & 1 & bndo & bndo & 1378 & Apr & 13 & 21:12 & README.org\\
-rw-rw-r-- & 1 & bndo & bndo & 2978 & Apr & 15 & 00:12 & report.bbl\\
-rw-rw-r-- & 1 & bndo & bndo & 10426 & Apr & 15 & 00:13 & report.org\\
-rw-rw-r-- & 1 & bndo & bndo & 700441 & Apr & 15 & 00:12 & report.pdf\\
-rw-rw-r-- & 1 & bndo & bndo & 9287 & Apr & 15 & 00:12 & report.tex\\
-rw-rw-r-- & 1 & bndo & bndo & 738 & Apr & 13 & 21:12 & template.bib\\
\end{tabular}
\end{center}


\section{Section 2}
\label{sec:org3a06ad6}
\newpage


selon une etude \cite{2021}

\newpage

\phantomsection
\addcontentsline{toc}{section}{Références}

\printbibliography
\end{document}
